{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65206ada-577e-42db-9580-ac6764505bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#having trouble getting the Inception model to run\n",
    "#error in slicing in model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87bef63c-6512-4a57-b81e-cc13846784e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.transforms import v2\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import inception_v3, Inception_V3_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc086ea-ff31-4ae3-aa86-b2d154564658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#good practice to provide class labels as integer arrays\n",
    "\n",
    "CLASSES = [\"BLD\", \"No BLD\"]\n",
    "class_mapping = {label: idx for idx, label in\n",
    "                 enumerate(np.unique([CLASSES]))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b32da4c-d5f3-4b9b-872f-f50c0e26a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictonary to modify transformations\n",
    "config = dict(\n",
    "    rot=90,\n",
    "    noise=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267e8ccc-1f45-4bc8-be02-866a3719eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure image input size matches expected size for the spcific models\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    #384x384 for efficientnet\n",
    "    #224x225 for ResNEt and MobileNEt\n",
    "    #299x299 for Inception V3 #https://pytorch.org/vision/main/models/generated/torchvision.models.inception_v3.html\n",
    "    #256x256 for Swin\n",
    "    [transforms.Resize([299,299]), #converts image to the pre-trained model dimension expectations\n",
    "     #transforms.RandomRotation(degrees=config[\"rot\"]),\n",
    "     #transforms.RandomVerticalFlip(p=0.5),\n",
    "     #transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.Grayscale(3),\n",
    "     transforms.ToTensor(), #Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),#this is a standard RGB mean and std\n",
    "    ])\n",
    "\n",
    "#validation preprocessing\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.Resize([299,299]), #converts image to the pre-trained model dimension expectations\n",
    "     transforms.Grayscale(3),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),#this is a standard RGB mean and std\n",
    "     ])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9de734-8086-4730-ad44-257c2289b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "#images in directories converted to tensor format and classes obtained from direcory names\n",
    "#add test folder once get more data\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='/project/90daydata/nematode_ml/BLD/NematodeDataset/train', transform=train_transform)\n",
    "#test_dataset = torchvision.datasets.ImageFolder(root='/project/90daydata/nematode_ml/BLD/NematodeDataset/test', transform=val_transform)\n",
    "val_dataset = torchvision.datasets.ImageFolder(root='/project/90daydata/nematode_ml/BLD/NematodeDataset/val', transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d0700-bd4a-44a8-a956-ff60fc5741f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the transformed image\n",
    "image, label = train_dataset[0]\n",
    "# Check the size of the transformed image\n",
    "print(image.shape) #retuns [channel, height, width]. 3 indicates color. During training an additional element is added, batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0d33a20-39b5-4413-9d34-0a70db7f818c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BLD': 0, 'No_BLD': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check class names\n",
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6aa013-ba06-40ee-8046-3b6a830ef764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of images in each set\n",
    "print(f'Number of images in training dataset: {len(train_dataset)}')\n",
    "#print(f'Number of images in testing dataset: {len(test_dataset)}')\n",
    "print(f'Number of images in validation dataset: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f491e6-46a4-49b2-91c4-64f9f488d82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bing\n",
    "#how to print example of each image class from dataset pytorch\n",
    "#fix unnormalize image in display\n",
    "\n",
    "# Create a dictionary to store one example per class\n",
    "class_examples = {}\n",
    "\n",
    "# Iterate through the dataset to find one example per class\n",
    "for img, label in train_dataset:\n",
    "    if label not in class_examples:\n",
    "        class_examples[label] = img\n",
    "    if len(class_examples) == len(train_dataset.classes):\n",
    "        break\n",
    "\n",
    "# Plot the examples\n",
    "fig, axes = plt.subplots(1, len(class_examples), figsize=(15, 5))\n",
    "for idx, (label, img) in enumerate(class_examples.items()):\n",
    "    axes[idx].imshow(img.permute(1, 2, 0))\n",
    "    axes[idx].set_title(train_dataset.classes[label])\n",
    "    axes[idx].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97efd7e0-3cb3-40b7-b48c-71176431654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a hyperparameter to try changing\n",
    "#batch_size = 4\n",
    "batch_size = 16\n",
    "#batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6a6181-8c16-4620-9568-383e3ff2ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader\n",
    "#output a batch of images and labels, one sample at a time\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "#testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "#                                         shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279a62b6-9411-4ccc-b082-7032b0740f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print class for each sample in batch\n",
    "train_features, train_labels = next(iter(trainloader))\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83588d3e-ceb3-4380-8859-331c61e92e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "#to pull out a single image and label, first put in individual variables\n",
    "#https://stackoverflow.com/questions/61480762/python-matplotlib-invalid-shape-for-image-data\n",
    "\n",
    "train_features, train_labels = next(iter(trainloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape (number): {train_labels.size()}\")\n",
    "img = train_features[0].numpy().transpose((1, 2, 0)) #changing the channel and dimension order for plotting\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "img = std * img + mean\n",
    "img = np.clip(img, 0, 1)\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {[CLASSES[label]]}\")\n",
    "print(f\"Label: {train_labels[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218a057-de50-4b5d-a7b4-9e5444ad8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(trainloader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[CLASSES[x] for x in classes])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7b1aa-5fe6-4515-9ce0-a500bde67247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "del optimizer\n",
    "del criterion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f9a02-26d3-4db0-a43b-4dc936c198c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea228e9e-5733-4a21-bb2f-686d08a24d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import model for training\n",
    "\n",
    "#Inception V3\n",
    "weights =Inception_V3_Weights.DEFAULT\n",
    "model_IN = torchvision.models.inception_v3(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27c5ad70-a1d0-43f6-b03d-0efe5cc38229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=2, bias=True)\n",
      "Linear(in_features=2048, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "#Inception V3\n",
    "#Intitalize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#freeze layers\n",
    "for param in model_IN.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "model_in = model_IN\n",
    "#look at structure of final classifier layers\n",
    "print(model_IN.fc)\n",
    "num_ftrs = model_in.fc.in_features #print this out to confirm a value\n",
    "\n",
    "num_classes = 2  # Replace with the number of classes in your dataset\n",
    "# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
    "model_in.fc = nn.Linear(in_features=model_in.fc.in_features, out_features=num_classes)\n",
    "print(model_in.fc)\n",
    "\n",
    "model_in = model_in.to(device) #move model to this device\n",
    "\n",
    "\n",
    "#Loss function\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss() \n",
    "criterion = nn.BCEWithLogitsLoss() #recommended for binary classificaion\n",
    "\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer = optim.SGD(model_ft.parameters(), lr=0.001)\n",
    "optimizer = optim.Adam(model_in.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71b8bfc7-5fe4-479e-8bb4-cb27583c65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pg. 479 pytorch book\n",
    "#modified to accomidate BCELoss format expectations in the pred output\n",
    "#Pg. 473\n",
    "#If returning 1 probablity from model(x_batch) (using [:,0]), then use BCE function\n",
    "#If retunring 2 proabability values, use Cross entropy loss function\n",
    "\n",
    "def train_1(model, num_epochs, train_d1, valid_d1):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() #set model to training mode\n",
    "        for x_batch, y_batch, in train_d1:\n",
    "            #output of forward pass a tensor with predictions for the batch\n",
    "            pred = model(x_batch)[:,0] #slicing the first column to make shapes match for BCE loss\n",
    "            #print(pred.size(), y_batch.size()) #use this to troubleshoot BCE error. Shapes should match\n",
    "            \n",
    "        #uncomment block\n",
    "            loss = criterion(pred, y_batch.float()) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            is_correct = ((pred>=0.5).float() == y_batch).float() #calculating correct class from first column of pred tensor [:,0]\n",
    "            accuracy_hist_train[epoch] += is_correct.sum()\n",
    "        loss_hist_train[epoch] /= len(train_d1.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_d1.dataset)\n",
    "        \n",
    "        model.eval() \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_d1:\n",
    "                pred = model(x_batch)[:,0] #slicing the first column to make shapes match for BCE loss\n",
    "                 #save probabilities from previously trained model\n",
    "                outputs = model(x_batch)\n",
    "\n",
    "                #saving largest probabilities in each batch\n",
    "                probs, preds = torch.max(outputs,1) \n",
    "                #print(probs)\n",
    "                #print(preds)\n",
    "                \n",
    "                \n",
    "               #uncomment block\n",
    "                loss = criterion(pred, y_batch.float()) #BCE expects floar\n",
    "                loss_hist_valid[epoch] += \\\n",
    "                    loss.item() * y_batch.size(0)\n",
    "                is_correct = \\\n",
    "                    ((pred>=0.5).float() == y_batch).float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum()\n",
    "            loss_hist_valid[epoch] /= len(valid_d1.dataset)\n",
    "            accuracy_hist_valid[epoch] /= len(valid_d1.dataset)\n",
    "\n",
    "            #Preparing data for evaluation\n",
    "            #append values in list after loop   \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "            #convert to np array  \n",
    "            #all_preds = np.array(all_preds)\n",
    "            #all_labels = np.array(all_labels)\n",
    "            \n",
    "            #all_preds = torch.tensor(all_preds)\n",
    "            all_labels = torch.tensor(all_labels)\n",
    "            #print(all_preds)\n",
    "            #print(all_labels)\n",
    "        \n",
    "\n",
    "            #uncomment block\n",
    "            print(f'Epoch {epoch+1} ' \n",
    "                  f'accuracy: {accuracy_hist_train[epoch]:.4f}, '\n",
    "                  f'val_accuracy: {accuracy_hist_valid[epoch]:.4f}, '\n",
    "                  f'train_loss: {loss_hist_train[epoch]:.4f}, '\n",
    "                  f'val_loss: {loss_hist_valid[epoch]:.4f} ')\n",
    "\n",
    "            \n",
    "\n",
    "    # Compute precision\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')  # Use 'micro', 'macro', or 'weighted' for multi-class\n",
    "    #calculate recall score\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    #Calculate f1 score\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    #need to confirm if sigmoid function is needed (all_predictions vs all_preds\n",
    "    #auc = roc_auc_score(all_labels, all_predictions)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "        \n",
    "                    \n",
    "\n",
    "    print(f'Precision Score: {precision:.4f}, '\n",
    "          f'Recall Score: {recall:.4f}, '\n",
    "          f'F1 Score: {f1:.4f}, '\n",
    "          f'ROC AUC: {auc:.4f}'\n",
    "            )    \n",
    "\n",
    "    #for graph\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_preds) \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    #plt.figure()  \n",
    "    #plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    #plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "    #plt.xlim([0.0, 1.0])\n",
    "    #plt.ylim([0.0, 1.05])\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    #plt.title('ROC Curve for Beech Leaf Disease Classification')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    #returns these values that can be stored in a variable when the function is run\n",
    "    return loss_hist_train, loss_hist_valid, \\\n",
    "        accuracy_hist_train, accuracy_hist_valid, \\\n",
    "        precision, recall, f1, fpr, tpr, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "804a1d15-1a29-4d82-8b8c-40cf4ccc2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pg. 479 pytorch book\n",
    "#modified to accomidate BCELoss format expectations in the pred output\n",
    "#Pg. 473\n",
    "#If returning 1 probablity from model(x_batch) (using [:,0]), then use BCE function\n",
    "#If retunring 2 proabability values, use Cross entropy loss function\n",
    "\n",
    "def train_1(model, num_epochs, train_d1, valid_d1):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() #set model to training mode\n",
    "        for x_batch, y_batch, in train_d1:\n",
    "            #output of forward pass a tensor with predictions for the batch\n",
    "            #pred = model(x_batch)[:,0] #slicing the first column to make shapes match for BCE loss\n",
    "            #print(pred.size(), y_batch.size()) #use this to troubleshoot BCE error. Shapes should match\n",
    "            output = model(x_batch)\n",
    "            _, pred = torch.max(output,1) \n",
    "            print(pred)\n",
    "            \n",
    "        #uncomment block\n",
    "            loss = criterion(pred, y_batch.float()) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            is_correct = ((pred>=0.5).float() == y_batch).float() #calculating correct class from first column of pred tensor [:,0]\n",
    "            accuracy_hist_train[epoch] += is_correct.sum()\n",
    "        loss_hist_train[epoch] /= len(train_d1.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_d1.dataset)\n",
    "        \n",
    "        model.eval() \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_d1:\n",
    "                pred = model(x_batch)[:,0] #slicing the first column to make shapes match for BCE loss\n",
    "                 #save probabilities from previously trained model\n",
    "                outputs = model(x_batch)\n",
    "\n",
    "                #saving largest probabilities in each batch\n",
    "                probs, preds = torch.max(outputs,1) \n",
    "                #print(probs)\n",
    "                #print(preds)\n",
    "                \n",
    "                \n",
    "               #uncomment block\n",
    "                loss = criterion(pred, y_batch.float()) #BCE expects floar\n",
    "                loss_hist_valid[epoch] += \\\n",
    "                    loss.item() * y_batch.size(0)\n",
    "                is_correct = \\\n",
    "                    ((pred>=0.5).float() == y_batch).float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum()\n",
    "            loss_hist_valid[epoch] /= len(valid_d1.dataset)\n",
    "            accuracy_hist_valid[epoch] /= len(valid_d1.dataset)\n",
    "\n",
    "            #Preparing data for evaluation\n",
    "            #append values in list after loop   \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "            #convert to np array  \n",
    "            #all_preds = np.array(all_preds)\n",
    "            #all_labels = np.array(all_labels)\n",
    "            \n",
    "            #all_preds = torch.tensor(all_preds)\n",
    "            all_labels = torch.tensor(all_labels)\n",
    "            #print(all_preds)\n",
    "            #print(all_labels)\n",
    "        \n",
    "\n",
    "            #uncomment block\n",
    "            print(f'Epoch {epoch+1} ' \n",
    "                  f'accuracy: {accuracy_hist_train[epoch]:.4f}, '\n",
    "                  f'val_accuracy: {accuracy_hist_valid[epoch]:.4f}, '\n",
    "                  f'train_loss: {loss_hist_train[epoch]:.4f}, '\n",
    "                  f'val_loss: {loss_hist_valid[epoch]:.4f} ')\n",
    "\n",
    "            \n",
    "\n",
    "    # Compute precision\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')  # Use 'micro', 'macro', or 'weighted' for multi-class\n",
    "    #calculate recall score\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    #Calculate f1 score\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    #need to confirm if sigmoid function is needed (all_predictions vs all_preds\n",
    "    #auc = roc_auc_score(all_labels, all_predictions)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "        \n",
    "                    \n",
    "\n",
    "    print(f'Precision Score: {precision:.4f}, '\n",
    "          f'Recall Score: {recall:.4f}, '\n",
    "          f'F1 Score: {f1:.4f}, '\n",
    "          f'ROC AUC: {auc:.4f}'\n",
    "            )    \n",
    "\n",
    "    #for graph\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_preds) \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    #plt.figure()  \n",
    "    #plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    #plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "    #plt.xlim([0.0, 1.0])\n",
    "    #plt.ylim([0.0, 1.05])\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    #plt.title('ROC Curve for Beech Leaf Disease Classification')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    #returns these values that can be stored in a variable when the function is run\n",
    "    return loss_hist_train, loss_hist_valid, \\\n",
    "        accuracy_hist_train, accuracy_hist_valid, \\\n",
    "        precision, recall, f1, fpr, tpr, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13414853-3ef0-45bc-9aac-8ec860d8ded4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (InceptionOutputs, int), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, Tensor other, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, tuple of Tensors out = None)\n * (Tensor input, name dim, bool keepdim = False, *, tuple of Tensors out = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 4\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mtrain_1\u001b[0;34m(model, num_epochs, train_d1, valid_d1)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch, \u001b[38;5;129;01min\u001b[39;00m train_d1:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#output of forward pass a tensor with predictions for the batch\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#pred = model(x_batch)[:,0] #slicing the first column to make shapes match for BCE loss\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#print(pred.size(), y_batch.size()) #use this to troubleshoot BCE error. Shapes should match\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[0;32m---> 20\u001b[0m     _, pred \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pred)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#uncomment block\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (InceptionOutputs, int), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, Tensor other, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, tuple of Tensors out = None)\n * (Tensor input, name dim, bool keepdim = False, *, tuple of Tensors out = None)\n"
     ]
    }
   ],
   "source": [
    "#Train model not frozen\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 10\n",
    "hist = train_1(model_in, num_epochs, trainloader, valloader)\n",
    "\n",
    "#print(len(hist))\n",
    "#print(hist[0:9])\n",
    "#saved variable 'hist' contains the values from each epoch of loss_hist_train [0],\n",
    "#loss_hist_valid [1], accuracy_hist_train [2], accuracy_hist_valid [3],\n",
    "#contains single value of precision [4], recall, [5], f1 [6], fpr [7], tpr [8], auc [9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9416974-b70d-4111-a21a-796b81268336",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision Score: {hist[4]}')\n",
    "print(f'Recall Score: {hist[5]}')\n",
    "print(f'F1 Score: {hist[6]}')\n",
    "print(f'False Positive Rate: {hist[7]}')\n",
    "print(f'True Positive Rate: {hist[8]}')\n",
    "print(f'ROC AUC: {hist[9]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8ccec-c7d5-4820-9dc4-ac3103eb47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "#fpr is hist[7]\n",
    "#tpr is hist[8]\n",
    "#roc_auc is hist[9]\n",
    "\n",
    "plt.figure()  \n",
    "plt.plot(hist[7], hist[8], label='ROC curve (area = %0.2f)' % hist[9])\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='50-50 guess')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Beech Leaf Disease Classification')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae94d10-d7f2-407b-90d5-0309fc91fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot learning curve\n",
    "x_arr = np.arange(len(hist[0])) + 1\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist[0], '-o', label='Train loss')\n",
    "ax.plot(x_arr, hist[1], '--<', label='Validation loss')\n",
    "ax.legend(fontsize = 15)\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist[2], '-o', label='Train accuracy')\n",
    "ax.plot(x_arr, hist[3], '--<',\n",
    "        label='Validation accuracy')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size = 15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d186a2-b940-45db-b47a-1933792b1be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb55a9-1783-4dc0-80d6-a305b3ec5a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel",
   "language": "python",
   "name": "ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
