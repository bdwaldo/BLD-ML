{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e076a5-c4a8-4659-b105-dc548cf8c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alexnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51845953-3436-40cf-bddd-1988d3961f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.transforms import v2\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import alexnet, AlexNet_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "426d836c-c2bd-4293-a95f-26fce9bfd76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#good practice to provide class labels as integer arrays\n",
    "\n",
    "CLASSES = [\"BLD\", \"No BLD\"]\n",
    "class_mapping = {label: idx for idx, label in\n",
    "                 enumerate(np.unique([CLASSES]))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2da0604f-13d4-4e15-b695-975206efe9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictonary to modify transformations\n",
    "config = dict(\n",
    "    rot=90,\n",
    "    noise=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d98490e4-b294-4697-ad7a-29da1c3a119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure image input size matches expected size for the spcific models\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    #384x384 for efficientnet\n",
    "    #224x224 for ResNEt and MobileNEt, Alexnet\n",
    "    #299x299 for Inception V3 #https://pytorch.org/vision/main/models/generated/torchvision.models.inception_v3.html\n",
    "    #256x256 for Swin\n",
    "    [transforms.Resize([224,224]), #converts image to the pre-trained model dimension expectations\n",
    "     #transforms.RandomRotation(degrees=config[\"rot\"]),\n",
    "     #transforms.RandomVerticalFlip(p=0.5),\n",
    "     #transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.Grayscale(3),\n",
    "     transforms.ToTensor(), #Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),#this is a standard RGB mean and std\n",
    "    ])\n",
    "\n",
    "#validation preprocessing\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.Resize([224,224]), #converts image to the pre-trained model dimension expectations\n",
    "     transforms.Grayscale(3),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),#this is a standard RGB mean and std\n",
    "     ])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edcf6362-7fff-4879-ba89-aa0f6a9ab93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "#images in directories converted to tensor format and classes obtained from direcory names\n",
    "#add test folder once get more data\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='/project/90daydata/nematode_ml/BLD/NematodeDataset/train', transform=train_transform)\n",
    "#test_dataset = torchvision.datasets.ImageFolder(root='/project/90daydata/nematode_ml/BLD/NematodeDataset/test', transform=val_transform)\n",
    "val_dataset = torchvision.datasets.ImageFolder(root='/project/90daydata/nematode_ml/BLD/NematodeDataset/val', transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24efb571-df86-441c-9a81-414974776fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Access the transformed image\n",
    "image, label = train_dataset[0]\n",
    "# Check the size of the transformed image\n",
    "print(image.shape) #retuns [channel, height, width]. 3 indicates color. During training an additional element is added, batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c56e7b-190b-47e4-8d1d-24e4427d5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check class names\n",
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366cfa13-61a3-4514-ae66-f141ea97b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of images in each set\n",
    "print(f'Number of images in training dataset: {len(train_dataset)}')\n",
    "#print(f'Number of images in testing dataset: {len(test_dataset)}')\n",
    "print(f'Number of images in validation dataset: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd66b771-d29d-44d0-95fd-e464b6e327f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bing\n",
    "#how to print example of each image class from dataset pytorch\n",
    "#loop through and get one image per class\n",
    "\n",
    "# Create a dictionary to store one example per class\n",
    "class_examples = {}\n",
    "\n",
    "# Iterate through the dataset to find one example per class\n",
    "#unpack img and label pair from train_dataset\n",
    "for img, label in train_dataset:\n",
    "    if label not in class_examples:\n",
    "        #if the label is not in the class_example dict, then store the image\n",
    "        class_examples[label] = img\n",
    "        #if the number of classes in class_examples equals the number of classes in the train_dataset, stop\n",
    "    if len(class_examples) == len(train_dataset.classes):\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b876f8c8-b9df-4a3e-9e4a-fbec53f1e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot one image from each class in dict 'class_example'\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "for label, img in class_examples.items():\n",
    "    #the dict structure is class label: image\n",
    "    #print(img)\n",
    "    #print(label)\n",
    "    #print(f\"Labels batch shape (number): {label.size()}\")\n",
    "\n",
    "    #create subplot shape\n",
    "    ax = fig.add_subplot(1,2, label+1)\n",
    "    img = img.numpy().transpose((1, 2, 0)) #changing the channel and dimension order for plotting\n",
    "    #img = img.numpy().transpose((0, 1, 2))\n",
    "    #print({img.size})\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    label = label\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    #print class title\n",
    "    ax.set_title(f\"Label: {CLASSES[label]}\")\n",
    "plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4804104b-3bc8-468f-9b5b-7034a8270398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a hyperparameter to try changing\n",
    "#batch_size = 4\n",
    "batch_size = 16\n",
    "#batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad523918-d2b8-4590-8b9b-521c9c7929f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader\n",
    "#output a batch of images and labels, one sample at a time\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "#testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "#                                         shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d51077b-fc3f-4735-8372-2d37d715ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print class for each sample in batch\n",
    "train_features, train_labels = next(iter(trainloader))\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e0aaa-2433-452b-85b6-066524f28348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "#to pull out a single image and label, first put in individual variables\n",
    "#https://stackoverflow.com/questions/61480762/python-matplotlib-invalid-shape-for-image-data\n",
    "\n",
    "train_features, train_labels = next(iter(trainloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape (number): {train_labels.size()}\")\n",
    "img = train_features[0].numpy().transpose((1, 2, 0)) #changing the channel and dimension order for plotting\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "img = std * img + mean\n",
    "img = np.clip(img, 0, 1)\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {[CLASSES[label]]}\")\n",
    "print(f\"Label: {train_labels[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3081da21-f541-4a36-be9d-8f891398b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(trainloader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[CLASSES[x] for x in classes])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250b27f-1e86-405f-9607-086f25bbdc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "del optimizer\n",
    "del criterion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256a0771-7e24-4a6b-9381-2581ba7cd49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c297d5a-85d0-4920-aa81-3768921a357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AlexNet\n",
    "weights=AlexNet_Weights.DEFAULT\n",
    "model_AN = torchvision.models.alexnet(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01ff3ec4-b3e3-412f-b40c-ba94bed714f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AlexNet\n",
    "\n",
    "#Intitalize model, not freezing layers\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_an = model_AN\n",
    "num_ftrs = model_an.classifier[6].in_features #print this out to confirm a value\n",
    "\n",
    "num_classes = 2  # Replace with the number of classes in your dataset\n",
    "# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
    "model_an.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "#move model to this device\n",
    "#model_an = model_an.to(device)\n",
    "\n",
    "\n",
    "#Loss function\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss() \n",
    "criterion = nn.BCEWithLogitsLoss() #recommended for binary classificaion\n",
    "\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer = optim.SGD(model_ft.parameters(), lr=0.001)\n",
    "optimizer = optim.Adam(model_an.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e679d0dc-78b2-451a-ab4e-eddf8686a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pg. 479 pytorch book\n",
    "#modified to accomidate BCELoss format expectations in the pred output\n",
    "#Pg. 473\n",
    "#If returning 1 probablity from model(x_batch) (using [:,0]), then use BCE function\n",
    "#If retunring 2 proabability values, use Cross entropy loss function\n",
    "\n",
    "def train_1(model, num_epochs, train_d1, valid_d1):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() #set model to training mode\n",
    "        for x_batch, y_batch, in train_d1:\n",
    "            #output of forward pass a tensor with predictions for the batch\n",
    "            pred = model(x_batch)[:,0] #slicing the first column to make shapes match for BCE loss\n",
    "            #print(pred.size(), y_batch.size()) #use this to troubleshoot BCE error. Shapes should match\n",
    "        \n",
    "        #uncomment block\n",
    "            loss = criterion(pred, y_batch.float()) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            is_correct = ((pred>=0.5).float() == y_batch).float() #calculating correct class from first column of pred tensor [:,0]\n",
    "            accuracy_hist_train[epoch] += is_correct.sum()\n",
    "        loss_hist_train[epoch] /= len(train_d1.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_d1.dataset)\n",
    "        \n",
    "        model.eval() \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_d1:\n",
    "                pred = model(x_batch)[:,0] #slicing the first column to make shapes match for BCE loss\n",
    "                 #save probabilities from previously trained model\n",
    "                #print(f'pred {pred}')\n",
    "                outputs = model(x_batch)\n",
    "\n",
    "                #saving largest probabilities in each batch\n",
    "                probs, preds = torch.max(outputs,1) \n",
    "                #print(probs)\n",
    "                print(f'preds {preds}')\n",
    "                \n",
    "                \n",
    "               #uncomment block\n",
    "                loss = criterion(pred, y_batch.float()) #BCE expects floar\n",
    "                loss_hist_valid[epoch] += \\\n",
    "                    loss.item() * y_batch.size(0)\n",
    "                is_correct = \\\n",
    "                    ((pred>=0.5).float() == y_batch).float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum()\n",
    "            loss_hist_valid[epoch] /= len(valid_d1.dataset)\n",
    "            accuracy_hist_valid[epoch] /= len(valid_d1.dataset)\n",
    "\n",
    "            #Preparing data for evaluation\n",
    "            #append values in list after loop   \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "            #convert to np array  \n",
    "            #all_preds = np.array(all_preds)\n",
    "            #all_labels = np.array(all_labels)\n",
    "            \n",
    "            #all_preds = torch.tensor(all_preds)\n",
    "            #all_labels = torch.tensor(all_labels)\n",
    "            print(f'all preds {all_preds}')\n",
    "            print(f'all labels {all_labels}')\n",
    "        \n",
    "\n",
    "            #uncomment block\n",
    "            print(f'Epoch {epoch+1} ' \n",
    "                  f'accuracy: {accuracy_hist_train[epoch]:.4f}, '\n",
    "                  f'val_accuracy: {accuracy_hist_valid[epoch]:.4f}, '\n",
    "                  f'train_loss: {loss_hist_train[epoch]:.4f}, '\n",
    "                  f'val_loss: {loss_hist_valid[epoch]:.4f} ')\n",
    "\n",
    "            \n",
    "\n",
    "    # Compute precision\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')  # Use 'micro', 'macro', or 'weighted' for multi-class\n",
    "    #calculate recall score\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    #Calculate f1 score\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    #need to confirm if sigmoid function is needed (all_predictions vs all_preds\n",
    "    #auc = roc_auc_score(all_labels, all_predictions)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "        \n",
    "                    \n",
    "\n",
    "    print(f'Precision Score: {precision:.4f}, '\n",
    "          f'Recall Score: {recall:.4f}, '\n",
    "          f'F1 Score: {f1:.4f}, '\n",
    "          f'ROC AUC: {auc:.4f}'\n",
    "            )    \n",
    "\n",
    "    #for graph\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_preds) \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    #plt.figure()  \n",
    "    #plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    #plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "    #plt.xlim([0.0, 1.0])\n",
    "    #plt.ylim([0.0, 1.05])\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    #plt.title('ROC Curve for Beech Leaf Disease Classification')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    #uncomment block\n",
    "    return loss_hist_train, loss_hist_valid, \\\n",
    "        accuracy_hist_train, accuracy_hist_valid, \\\n",
    "        precision, recall, f1, fpr, tpr, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cc16f73-bce8-46b4-b76b-51fff9cfce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "preds tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      " all preds [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " all labels [0, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "Epoch 1 accuracy: 0.6375, val_accuracy: 0.6154, train_loss: 1.3035, val_loss: 0.6126 \n",
      "Precision Score: 0.3000, Recall Score: 1.0000, F1 Score: 0.4615, ROC AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "#Train model not frozen\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 1\n",
    "hist = train_1(model_an, num_epochs, trainloader, valloader)\n",
    "\n",
    "#print(len(hist))\n",
    "#print(hist[0:9])\n",
    "#saved variable 'hist' contains the values from each epoch of loss_hist_train [0],\n",
    "#loss_hist_valid [1], accuracy_hist_train [2], accuracy_hist_valid [3],\n",
    "#contains single value of precision [4], recall, [5], f1 [6], fpr [7], tpr [8], auc [9]3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09baaf5-dc87-44b3-8756-580509aba2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision Score: {hist[4]}')\n",
    "print(f'Recall Score: {hist[5]}')\n",
    "print(f'F1 Score: {hist[6]}')\n",
    "print(f'False Positive Rate: {hist[7]}')\n",
    "print(f'True Positive Rate: {hist[8]}')\n",
    "print(f'ROC AUC: {hist[9]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c946a3b-3d33-43cb-95b2-7f9951a6bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "#fpr is hist[7]\n",
    "#tpr is hist[8]\n",
    "#roc_auc is hist[9]\n",
    "\n",
    "plt.figure()  \n",
    "plt.plot(hist[7], hist[8], label='ROC curve (area = %0.2f)' % hist[9])\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='50-50 guess')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Beech Leaf Disease Classification')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5372e-8c05-4628-9401-03388a6f8da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot learning curve\n",
    "x_arr = np.arange(len(hist[0])) + 1\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist[0], '-o', label='Train loss')\n",
    "ax.plot(x_arr, hist[1], '--<', label='Validation loss')\n",
    "ax.legend(fontsize = 15)\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist[2], '-o', label='Train accuracy')\n",
    "ax.plot(x_arr, hist[3], '--<',\n",
    "        label='Validation accuracy')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size = 15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17928a7c-975e-41af-9bda-51557778a39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel",
   "language": "python",
   "name": "ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
