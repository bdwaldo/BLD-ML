{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2249f5a-bbda-45d9-9f2e-81fe1af9880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.transforms import v2\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baffb3e9-03f6-4bd8-ae9b-ab050775d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#good practice to provide class labels as integer arrays\n",
    "\n",
    "CLASSES = [\"BLD\", \"No BLD\"]\n",
    "class_mapping = {label: idx for idx, label in\n",
    "                 enumerate(np.unique([CLASSES]))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf60173-e0de-4559-ac12-48a548b6c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictonary to modify transformations\n",
    "config = dict(\n",
    "    rot=90,\n",
    "    noise=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b57b88-1d6f-466e-b25a-4f014745e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure image input size matches expected size for the spcific models\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    #384x384 for efficientnet\n",
    "    #224x224 for ResNEt and MobileNEt\n",
    "    #299x299 for Inception V3 #https://pytorch.org/vision/main/models/generated/torchvision.models.inception_v3.html\n",
    "    #256x256 for Swin\n",
    "    [transforms.Resize([224,224]), #converts image to the pre-trained model dimension expectations\n",
    "     #transforms.RandomRotation(degrees=config[\"rot\"]),\n",
    "     #transforms.RandomVerticalFlip(p=0.5),\n",
    "     #transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.Grayscale(3),\n",
    "     transforms.ToTensor(), #Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),#this is a standard RGB mean and std\n",
    "    ])\n",
    "\n",
    "#validation preprocessing\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.Resize([224,224]), #converts image to the pre-trained model dimension expectations\n",
    "     transforms.Grayscale(3),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),#this is a standard RGB mean and std\n",
    "     ])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab62c61b-5cae-481c-89b9-a138c4196883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "#images in directories converted to tensor format and classes obtained from direcory names\n",
    "#add test folder once get more data\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='/project/90daydata/nematode_ml/BLD/NematodeDataset/train', transform=train_transform)\n",
    "#test_dataset = torchvision.datasets.ImageFolder(root='/project/90daydata/nematode_ml/BLD/NematodeDataset/test', transform=val_transform)\n",
    "val_dataset = torchvision.datasets.ImageFolder(root='/project/90daydata/nematode_ml/BLD/NematodeDataset/val', transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d876ce-1184-4730-b127-d3ac575445f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Access the transformed image\n",
    "image, label = train_dataset[0]\n",
    "# Check the size of the transformed image\n",
    "print(image.shape) #retuns [channel, height, width]. 3 indicates color. During training an additional element is added, batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e0c883-8411-459d-867c-3873df26cd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BLD': 0, 'No_BLD': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check class names\n",
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e99e43-a2cc-43a8-851f-dd1b694c85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of images in each set\n",
    "print(f'Number of images in training dataset: {len(train_dataset)}')\n",
    "#print(f'Number of images in testing dataset: {len(test_dataset)}')\n",
    "print(f'Number of images in validation dataset: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9278f14-70f1-483d-99a5-3b58e8d9fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bing\n",
    "#how to print example of each image class from dataset pytorch\n",
    "#fix unnormalize image in display\n",
    "\n",
    "# Create a dictionary to store one example per class\n",
    "class_examples = {}\n",
    "\n",
    "# Iterate through the dataset to find one example per class\n",
    "for img, label in train_dataset:\n",
    "    if label not in class_examples:\n",
    "        class_examples[label] = img\n",
    "    if len(class_examples) == len(train_dataset.classes):\n",
    "        break\n",
    "\n",
    "# Plot the examples\n",
    "fig, axes = plt.subplots(1, len(class_examples), figsize=(15, 5))\n",
    "for idx, (label, img) in enumerate(class_examples.items()):\n",
    "    axes[idx].imshow(img.permute(1, 2, 0))\n",
    "    axes[idx].set_title(train_dataset.classes[label])\n",
    "    axes[idx].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dfb6d8a-0e91-4e82-8d85-9bcd990eadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a hyperparameter to try changing\n",
    "#batch_size = 4\n",
    "batch_size = 16\n",
    "#batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13425617-66cf-42a3-946a-c42a60054039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader\n",
    "#output a batch of images and labels, one sample at a time\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "#testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "#                                         shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f492c-6e71-4f9b-bc1b-b19925edcd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print class for each sample in batch\n",
    "train_features, train_labels = next(iter(trainloader))\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cb45a-b887-424e-a43f-7ae20e46beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "#to pull out a single image and label, first put in individual variables\n",
    "#https://stackoverflow.com/questions/61480762/python-matplotlib-invalid-shape-for-image-data\n",
    "\n",
    "train_features, train_labels = next(iter(trainloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape (number): {train_labels.size()}\")\n",
    "img = train_features[0].numpy().transpose((1, 2, 0)) #changing the channel and dimension order for plotting\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "img = std * img + mean\n",
    "img = np.clip(img, 0, 1)\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {[CLASSES[label]]}\")\n",
    "print(f\"Label: {train_labels[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0a9e3e-6bd1-4edf-af47-d5591e8dbbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(trainloader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[CLASSES[x] for x in classes])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11606bf-b63c-4b68-b759-e05e1536da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "del optimizer\n",
    "del criterion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b256e7-b8b3-4d51-b075-61a08f999336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9305e4af-24db-4e3d-ba9b-482c1aa1d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MobileNet\n",
    "# Small\n",
    "weights = MobileNet_V3_Small_Weights.DEFAULT\n",
    "model_MNs = mobilenet_v3_small(weights=weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bfb0795b-8f95-460f-b13d-0053b14a1b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n",
      "Linear(in_features=576, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "#MobileNet small\n",
    "\n",
    "#Intitalize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "####################\n",
    "#FOR SOME REASON MOBILENET ONLY RUNS IF I SET THIS TO TRUE\n",
    "#https://discuss.pytorch.org/t/pretraining-with-mobilenetv3/116992/2\n",
    "#https://discuss.pytorch.org/t/model-backward-runtimeerror-element-0-of-tensors-does-not-require-grad-and-does-not-have-a-grad-fn/139929/4\n",
    "####################\n",
    "#for param in model_MNs.parameters():\n",
    "#    param.requires_grad = True\n",
    "\n",
    "model_mns = model_MNs\n",
    "num_ftrs = model_mns.classifier[0].in_features #print this out to confirm a value\n",
    "print(num_ftrs)\n",
    "\n",
    "num_classes = 2  # Replace with the number of classes in your dataset\n",
    "# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
    "model_mns.fc = nn.Linear(num_ftrs, num_classes)\n",
    "print(model_mns.fc)\n",
    "\n",
    "#move model to this device\n",
    "model_mns = model_mns.to(device)\n",
    "\n",
    "\n",
    "\n",
    "#Loss function\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss() \n",
    "criterion = nn.BCEWithLogitsLoss() #recommended for binary classificaion\n",
    "\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer = optim.SGD(model_ft.parameters(), lr=0.001)\n",
    "optimizer = optim.Adam(model_mns.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "#Loss function\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss() \n",
    "criterion = nn.BCEWithLogitsLoss() #recommended for binary classificaion\n",
    "\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer = optim.SGD(model_ft.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model_mns.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model_mns.fc.parameters(),lr=0.001)\n",
    "\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0b737e9e-cb20-41a6-9258-cec8f4524cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "############################\n",
    "#MAY NEED TO APPLY SIGMOID FUNCTION TO MODEL PREDICTION OUTPUTS\n",
    "###########################\n",
    "\n",
    "#Pg. 479 pytorch book\n",
    "#modified to accomidate BCELoss format expectations in the pred output\n",
    "#Pg. 473\n",
    "#If returning 1 probablity from model(x_batch) (using [:,0]), then use BCE function\n",
    "#If retunring 2 proabability values, use Cross entropy loss function\n",
    "\n",
    "def train_1(model, num_epochs, train_d1, valid_d1):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() #set model to training mode\n",
    "        for x_batch, y_batch, in train_d1:\n",
    "            #output of forward pass a tensor with predictions for the batch\n",
    "            pred = model(x_batch)[:,0] #slicing the first column to make shapes match for BCE loss\n",
    "            #print(pred.size(), y_batch.size()) #use this to troubleshoot BCE error. Shapes should match\n",
    "\n",
    "            \n",
    "        #uncomment block\n",
    "            loss = criterion(pred, y_batch.float()) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            is_correct = ((pred>=0.5).float() == y_batch).float() #calculating correct class from first column of pred tensor [:,0]\n",
    "            accuracy_hist_train[epoch] += is_correct.sum()\n",
    "        loss_hist_train[epoch] /= len(train_d1.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_d1.dataset)\n",
    "\n",
    "           \n",
    "        model.eval() \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_d1:\n",
    "                pred = model(x_batch)[:,0] #slicing the first column to make shapes match for BCE loss\n",
    "                #save probabilities from previously trained model\n",
    "                outputs = model(x_batch)\n",
    "\n",
    "                #saving largest probabilities in each batch\n",
    "                probs, preds = torch.max(outputs,1) \n",
    "                print(probs)\n",
    "                print(preds)\n",
    "                \n",
    "                \n",
    "               #uncomment block\n",
    "                loss = criterion(pred, y_batch.float()) #BCE expects floar\n",
    "                loss_hist_valid[epoch] += \\\n",
    "                    loss.item() * y_batch.size(0)\n",
    "                is_correct = \\\n",
    "                    ((pred>=0.5).float() == y_batch).float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum()\n",
    "            loss_hist_valid[epoch] /= len(valid_d1.dataset)\n",
    "            accuracy_hist_valid[epoch] /= len(valid_d1.dataset)\n",
    "\n",
    "            #Preparing data for evaluation\n",
    "            #append values in list after loop   \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "            #convert to np array  \n",
    "            #all_preds = np.array(all_preds)\n",
    "            #all_labels = np.array(all_labels)\n",
    "            \n",
    "            #all_preds = torch.tensor(all_preds)\n",
    "            all_labels = torch.tensor(all_labels)\n",
    "            \n",
    "            print(all_preds)\n",
    "            print(all_labels)\n",
    "        \n",
    "\n",
    "            #uncomment block\n",
    "            print(f'Epoch {epoch+1} ' \n",
    "                  f'accuracy: {accuracy_hist_train[epoch]:.4f}, '\n",
    "                  f'val_accuracy: {accuracy_hist_valid[epoch]:.4f}, '\n",
    "                  f'train_loss: {loss_hist_train[epoch]:.4f}, '\n",
    "                  f'val_loss: {loss_hist_valid[epoch]:.4f} ')\n",
    "\n",
    "            \n",
    "\n",
    "    # Compute precision\n",
    "    #REMOVING \"average = 'binary'\"\n",
    "    precision = precision_score(all_labels.numpy(), all_preds)  # default average = 'binary'. Use 'micro', 'macro', or 'weighted' for multi-class\n",
    "    #calculate recall score\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    #Calculate f1 score\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    #need to confirm if sigmoid function is needed (all_predictions vs all_preds\n",
    "    #auc = roc_auc_score(all_labels, all_predictions)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "        \n",
    "                    \n",
    "\n",
    "    print(f'Precision Score: {precision:.4f}, '\n",
    "          f'Recall Score: {recall:.4f}, '\n",
    "          f'F1 Score: {f1:.4f}, '\n",
    "          f'ROC AUC: {auc:.4f}'\n",
    "            )    \n",
    "\n",
    "    #for graph\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_preds) \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    #plt.figure()  \n",
    "    #plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    #plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "    #plt.xlim([0.0, 1.0])\n",
    "    #plt.ylim([0.0, 1.05])\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    #plt.title('ROC Curve for Beech Leaf Disease Classification')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    #returns these values that can be stored in a variable when the function is run\n",
    "    return loss_hist_train, loss_hist_valid, \\\n",
    "        accuracy_hist_train, accuracy_hist_valid, \\\n",
    "        precision, recall, f1, fpr, tpr, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3a43ae71-30cf-4f7d-96e1-d726861cd4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pg. 479 pytorch book\n",
    "#modified to accomidate BCELoss format expectations in the pred output\n",
    "#Pg. 473\n",
    "#If returning 1 probablity from model(x_batch) (using [:,0]), then use BCE function\n",
    "#If retunring 2 proabability values, use Cross entropy loss function\n",
    "\n",
    "def train_1(model, num_epochs, train_d1, valid_d1):\n",
    "  \n",
    "        model.eval() \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_d1:\n",
    "                pred = model(x_batch)[:,0] #slicing the first column to make shapes match for BCE loss\n",
    "                 #save probabilities from previously trained model\n",
    "                outputs = model(x_batch)\n",
    "\n",
    "                #saving largest probabilities in each batch\n",
    "                probs, preds = torch.max(outputs,1) \n",
    "                preds = torch.sigmoid(outputs) > 0.5\n",
    "                #print(probs)\n",
    "                #print(preds)\n",
    "                #Preparing data for evaluation\n",
    "                #append values in list after loop   \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(y_batch.cpu().numpy())\n",
    "            \n",
    "\n",
    "\n",
    "            all_logits = torch.tensor(outputs, device=\"cpu\", dtype=torch.float)\n",
    "            all_preds = torch.tensor(all_preds, device=\"cpu\", dtype=torch.long)\n",
    "            all_labels = torch.tensor(all_labels, device=\"cpu\", dtype=torch.long)\n",
    "\n",
    "           \n",
    "        \n",
    "            \n",
    "\n",
    "    # Compute precision\n",
    "            precision = precision_score(all_labels, all_preds, average='binary')  # Use 'micro', 'macro', or 'weighted' for multi-class\n",
    "    #calculate recall score\n",
    "            recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    #Calculate f1 score\n",
    "            f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    #need to confirm if sigmoid function is needed (all_predictions vs all_preds\n",
    "    #auc = roc_auc_score(all_labels, all_predictions)\n",
    "            auc = roc_auc_score(all_labels, all_preds)\n",
    "        \n",
    "                    \n",
    "\n",
    "            print(f'Precision Score: {precision:.4f}, '\n",
    "                  f'Recall Score: {recall:.4f}, '\n",
    "                  f'F1 Score: {f1:.4f}, '\n",
    "                  f'ROC AUC: {auc:.4f}'\n",
    "            )    \n",
    "\n",
    "\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    #plt.figure()  \n",
    "    #plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    #plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "    #plt.xlim([0.0, 1.0])\n",
    "    #plt.ylim([0.0, 1.05])\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    #plt.title('ROC Curve for Beech Leaf Disease Classification')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "753ba6d6-a2b0-4650-90e4-2a2fd1844004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scratch/benjamin.waldo/17434837/ipykernel_3193484/2558747182.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  all_logits = torch.tensor(outputs, device=\"cpu\", dtype=torch.float)\n",
      "/local/scratch/benjamin.waldo/17434837/ipykernel_3193484/2558747182.py:32: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  all_preds = torch.tensor(all_preds, device=\"cpu\", dtype=torch.long)\n",
      "/local/scratch/benjamin.waldo/17434837/ipykernel_3193484/2558747182.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  all_preds = torch.tensor(all_preds, device=\"cpu\", dtype=torch.long)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [180]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [179]\u001b[0m, in \u001b[0;36mtrain_1\u001b[0;34m(model, num_epochs, train_d1, valid_d1)\u001b[0m\n\u001b[1;32m     33\u001b[0m         all_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(all_labels, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Compute precision\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m         precision \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use 'micro', 'macro', or 'weighted' for multi-class\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#calculate recall score\u001b[39;00m\n\u001b[1;32m     42\u001b[0m         recall \u001b[38;5;241m=\u001b[39m recall_score(all_labels, all_preds, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/project/nematode_ml/envs/ipykernel/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1757\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_score\u001b[39m(\n\u001b[1;32m   1629\u001b[0m     y_true,\n\u001b[1;32m   1630\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1637\u001b[0m ):\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1639\u001b[0m \n\u001b[1;32m   1640\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/project/nematode_ml/envs/ipykernel/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1544\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1547\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/project/nematode_ml/envs/ipykernel/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1348\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1348\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/project/nematode_ml/envs/ipykernel/lib/python3.8/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "#Train model not frozen\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 1\n",
    "hist = train_1(model_mns, num_epochs, trainloader, valloader)\n",
    "\n",
    "#print(len(hist))\n",
    "#print(hist[0:9])\n",
    "#saved variable 'hist' contains the values from each epoch of loss_hist_train [0],\n",
    "#loss_hist_valid [1], accuracy_hist_train [2], accuracy_hist_valid [3],\n",
    "#contains single value of precision [4], recall, [5], f1 [6], fpr [7], tpr [8], auc [9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c37c20-6a3e-4123-a5e6-00a19da1688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision Score: {hist[4]}')\n",
    "print(f'Recall Score: {hist[5]}')\n",
    "print(f'F1 Score: {hist[6]}')\n",
    "print(f'False Positive Rate: {hist[7]}')\n",
    "print(f'True Positive Rate: {hist[8]}')\n",
    "print(f'ROC AUC: {hist[9]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f9210880-79fb-4492-b798-b16c2b1f3e53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [131]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot the ROC curve\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#fpr is hist[7]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#tpr is hist[8]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#roc_auc is hist[9]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()  \n\u001b[0;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhist\u001b[49m[\u001b[38;5;241m7\u001b[39m], hist[\u001b[38;5;241m8\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROC curve (area = \u001b[39m\u001b[38;5;132;01m%0.2f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m hist[\u001b[38;5;241m9\u001b[39m])\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk--\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m50-50 guess\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlim([\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the ROC curve\n",
    "#fpr is hist[7]\n",
    "#tpr is hist[8]\n",
    "#roc_auc is hist[9]\n",
    "\n",
    "plt.figure()  \n",
    "plt.plot(hist[7], hist[8], label='ROC curve (area = %0.2f)' % hist[9])\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='50-50 guess')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Beech Leaf Disease Classification')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "21b5d294-c95b-4c35-ad34-8c461afc2a83",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [132]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Plot learning curve\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[43mhist\u001b[49m[\u001b[38;5;241m0\u001b[39m])) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      3\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      4\u001b[0m ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "#Plot learning curve\n",
    "x_arr = np.arange(len(hist[0])) + 1\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist[0], '-o', label='Train loss')\n",
    "ax.plot(x_arr, hist[1], '--<', label='Validation loss')\n",
    "ax.legend(fontsize = 15)\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist[2], '-o', label='Train accuracy')\n",
    "ax.plot(x_arr, hist[3], '--<',\n",
    "        label='Validation accuracy')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size = 15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed76edb-6aed-4159-ade7-38b625a0946f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel",
   "language": "python",
   "name": "ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
